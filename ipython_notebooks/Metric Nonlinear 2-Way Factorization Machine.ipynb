{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "goal:\n",
    "=====\n",
    "\n",
    "to build a model takes sparse X = x_{i,j} with i in [0,n], j in [0,m] and y, a n-dimensional label vector. we then build a k-rank latent representation of the i's and j's such that we minimize ||y_i - \\sum_i u_i * v_j||, an inner product that minimizes loss between an example's label and an inner product between the item's embedding and the embedding induced by all item factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import this stuff\n",
    "import time\n",
    "import sys\n",
    "from pylab import *\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import roc_auc_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def factorize(observed_features,\n",
    "              labels,\n",
    "              observed_features_validation,\n",
    "              labels_validation,\n",
    "              rank,\n",
    "              max_iter=100,\n",
    "              verbose=False,\n",
    "              lambda_v=0,\n",
    "              lambda_k=0,\n",
    "              lambda_w=0,\n",
    "              lambda_constants=0,\n",
    "              epsilon=0.001,\n",
    "              optimizer=tf.train.AdamOptimizer(),\n",
    "              seed=12345):\n",
    "\n",
    "    # Extract info about shapes etc from the training data\n",
    "    num_items = observed_features.shape[0]\n",
    "    num_features = observed_features.shape[1]\n",
    " \n",
    "    V = tf.Variable(tf.truncated_normal([rank, num_features], stddev=0.2, mean=0, seed=seed), name=\"feature_explainers\")\n",
    "    K = tf.Variable(tf.truncated_normal([rank, rank], stddev=0.2, mean=0, seed=seed), name=\"metric_matrix\")\n",
    "    \n",
    "    w = tf.Variable(tf.truncated_normal([1, num_features], stddev=0.2, mean=0, seed=seed), name=\"hyperplane\")\n",
    "    b_one = tf.Variable(tf.truncated_normal([1, 1], stddev=0.2, mean=0, seed=seed), name=\"b_one\")\n",
    "    b_two = tf.Variable(tf.truncated_normal([rank, 1], stddev=0.2, mean=0, seed=seed), name=\"b_two\")\n",
    "   \n",
    "    x = tf.placeholder(tf.float32, [None, num_features])\n",
    "    y = tf.placeholder(tf.float32)\n",
    "    \n",
    "    norm_x = tf.nn.l2_normalize(x, dim=0)\n",
    "    Vx = tf.matmul(V, tf.transpose(norm_x))\n",
    "    right_kern = tf.matmul(K, Vx)\n",
    "    \n",
    "    full_kern = tf.matmul(tf.transpose(Vx), right_kern)\n",
    "    linear = tf.matmul(w, tf.transpose(norm_x))\n",
    "\n",
    "    pred = tf.reduce_sum(tf.sigmoid(linear + full_kern + b_one))\n",
    "    \n",
    "    cost = tf.reduce_mean(-y*tf.log(pred + 0.0000000001) - (1-y)*tf.log((1-pred + 0.0000000001)) + \n",
    "            lambda_v*tf.nn.l2_loss(V) +\n",
    "            lambda_k*tf.nn.l2_loss(K) +\n",
    "            lambda_w*tf.nn.l2_loss(w) +\n",
    "            lambda_constants*(tf.nn.l2_loss(b_one) + tf.nn.l2_loss(b_two)))\n",
    "    optimize = optimizer.minimize(cost)\n",
    "    norm = tf.reduce_mean(tf.nn.l2_loss(V))\n",
    "    \n",
    "    init = tf.initialize_all_variables()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        last_cost = 1000000\n",
    "        for iter in range(0, max_iter):\n",
    "            avg_cost = 0\n",
    "            \n",
    "            for i in range(num_items):\n",
    "                _, c, n = sess.run([optimize, cost, norm],\n",
    "                              feed_dict={x:observed_features[i].reshape(1, num_features), y:labels[i]})\n",
    "                avg_cost += c / num_items\n",
    "            if verbose:\n",
    "                print(\"epoch: %s, cost: %s\" % (iter+1, avg_cost))\n",
    "\n",
    "            # check for convergence\n",
    "            if abs(avg_cost-last_cost)/avg_cost < epsilon:\n",
    "                break\n",
    "                \n",
    "            last_cost = avg_cost\n",
    "            \n",
    "        if verbose:\n",
    "            print(\"optimization finished\")\n",
    "        predictions = []\n",
    "        total_costs = 0\n",
    "        for i in range(observed_features_validation.shape[0]):\n",
    "            p, c = sess.run([pred, cost], feed_dict={x:observed_features_validation[i].reshape(1, num_features), y:labels_validation[i]})\n",
    "            predictions.append(p)\n",
    "            total_costs += c\n",
    "        return predictions, total_costs/observed_features_validation.shape[0], sess.run([norm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use this data for now\n",
    "\n",
    "categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']\n",
    "\n",
    "ng = datasets.fetch_20newsgroups (categories=categories, shuffle=True)\n",
    "labels = [1 if y == 2 else 0 for y in ng.target.reshape(-1,1)]\n",
    "\n",
    "tfidf = TfidfVectorizer(decode_error=False, min_df=5)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(ng.data, labels, test_size=.3)\n",
    "X_train = tfidf.fit_transform(X_train).todense()\n",
    "X_test = tfidf.transform(X_test).todense()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, cost: 3.75391443324\n",
      "epoch: 2, cost: 1.62003940619\n",
      "epoch: 3, cost: 0.81954680722\n",
      "epoch: 4, cost: 0.536505232211\n",
      "epoch: 5, cost: 0.274589249488\n",
      "epoch: 6, cost: 0.119419387572\n",
      "epoch: 7, cost: 0.122870589877\n",
      "epoch: 8, cost: 0.0632979819354\n",
      "epoch: 9, cost: 0.0384637217643\n",
      "epoch: 10, cost: 0.0217394864427\n",
      "epoch: 11, cost: 0.016056142326\n",
      "epoch: 12, cost: 0.0841576523835\n",
      "epoch: 13, cost: 0.401039653899\n",
      "epoch: 14, cost: 0.232459521873\n",
      "epoch: 15, cost: 0.135635185631\n",
      "epoch: 16, cost: 0.0875181458086\n",
      "epoch: 17, cost: 0.117795747342\n",
      "epoch: 18, cost: 0.0680810926627\n",
      "epoch: 19, cost: 0.0375784877906\n",
      "epoch: 20, cost: 0.00865280427814\n",
      "epoch: 21, cost: 0.00287496649456\n",
      "epoch: 22, cost: 0.00126928628858\n",
      "epoch: 23, cost: 0.000712680345559\n",
      "epoch: 24, cost: 0.000513330437957\n",
      "epoch: 25, cost: 0.000375097626271\n",
      "epoch: 26, cost: 0.000274019904129\n",
      "epoch: 27, cost: 0.000200889689943\n",
      "epoch: 28, cost: 0.000148125926391\n",
      "epoch: 29, cost: 0.000109910479358\n",
      "epoch: 30, cost: 8.20745377333e-05\n",
      "epoch: 31, cost: 6.16610144945e-05\n",
      "epoch: 32, cost: 4.65885872701e-05\n",
      "epoch: 33, cost: 3.53713688698e-05\n",
      "epoch: 34, cost: 2.69583073614e-05\n",
      "epoch: 35, cost: 2.06402819738e-05\n",
      "epoch: 36, cost: 1.58580720998e-05\n",
      "epoch: 37, cost: 1.22223552245e-05\n",
      "epoch: 38, cost: 9.45612556083e-06\n",
      "epoch: 39, cost: 7.34352968556e-06\n",
      "epoch: 40, cost: 5.72479466369e-06\n",
      "epoch: 41, cost: 4.48456061476e-06\n",
      "epoch: 42, cost: 3.52932218812e-06\n",
      "epoch: 43, cost: 2.79356498407e-06\n",
      "epoch: 44, cost: 2.22642799794e-06\n",
      "epoch: 45, cost: 1.78588637072e-06\n",
      "epoch: 46, cost: 1.44791672774e-06\n",
      "epoch: 47, cost: 1.18284913866e-06\n",
      "epoch: 48, cost: 9.78779261702e-07\n",
      "epoch: 49, cost: 8.18749173741e-07\n",
      "epoch: 50, cost: 6.95182240754e-07\n",
      "epoch: 51, cost: 5.9793319346e-07\n",
      "epoch: 52, cost: 5.23104748745e-07\n",
      "epoch: 53, cost: 4.63787096654e-07\n",
      "epoch: 54, cost: 4.17093235109e-07\n",
      "epoch: 55, cost: 3.82311665755e-07\n",
      "epoch: 56, cost: 3.52821342143e-07\n",
      "epoch: 57, cost: 3.30563826941e-07\n",
      "epoch: 58, cost: 3.12691402626e-07\n",
      "epoch: 59, cost: 2.99220965229e-07\n",
      "epoch: 60, cost: 2.87940043501e-07\n",
      "epoch: 61, cost: 2.78657296034e-07\n",
      "epoch: 62, cost: 2.7161545227e-07\n",
      "epoch: 63, cost: 2.66769798418e-07\n",
      "epoch: 64, cost: 2.61745819056e-07\n",
      "epoch: 65, cost: 2.58141674548e-07\n",
      "epoch: 66, cost: 2.55588798295e-07\n",
      "epoch: 67, cost: 2.53726398843e-07\n",
      "epoch: 68, cost: 2.5205582199e-07\n",
      "epoch: 69, cost: 2.50502792027e-07\n",
      "epoch: 70, cost: 2.48999744924e-07\n",
      "epoch: 71, cost: 2.48018560258e-07\n",
      "epoch: 72, cost: 2.4729865679e-07\n",
      "epoch: 73, cost: 2.46365819441e-07\n",
      "epoch: 74, cost: 2.46148875318e-07\n",
      "optimization finished\n",
      "rank: 10, cost: 0.214328299088, overall AUC: 0.988466588193, norm: [2.3070097e-05]\n"
     ]
    }
   ],
   "source": [
    "r = 10\n",
    "predictions, test_costs, norm = factorize(X_train, y_train, X_test, y_test, r, verbose=True, lambda_v=0.01, max_iter=300)\n",
    "print(\"rank: %s, cost: %s, overall AUC: %s, norm: %s\") % (r, test_costs, roc_auc_score(y_test, predictions, average=\"weighted\"), norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
